
                                                       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                                                      â–‘â–‘â–ˆâ–ˆâ–ˆ                â–‘â–‘â–ˆâ–ˆâ–ˆ
     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    â–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆ  â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆ â–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆ  â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–‘
     â–‘â–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–‘â–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆâ–‘â–ˆâ–ˆâ–ˆ â–‘â–‘â–‘  â–‘â–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–‘â–ˆâ–ˆâ–ˆ
     â–‘â–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆ  â–‘â–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆâ–‘â–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆ â–‘â–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆ  â–‘â–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆ
     â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    â–‘â–‘â–‘â–‘ â–‘â–‘â–‘â–‘â–‘  â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â–‘â–‘â–‘â–‘ â–‘â–‘â–‘â–‘â–‘  â–‘â–‘â–‘â–‘â–‘â–‘   â–‘â–‘â–‘â–‘â–‘â–‘  â–‘â–‘â–‘â–‘ â–‘â–‘â–‘â–‘â–‘  â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   â–‘â–‘â–‘â–‘â–‘
    
Overriding: model_size = small-4096
Overriding: model_tag = small4096_workflow_v2
Autodetected device type: cuda
/home/josch/git/nanochat-tct/.venv/lib/python3.12/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
  _C._set_float32_matmul_precision(precision)
2025-11-09 20:01:31,806 - nanochat.common - [32m[1mINFO[0m - Distributed world size: 1
Model: small-4096
Vocab size: 8192
Context size: 4096
Batch size: 8
Gradient accumulation: 16
Effective batch size: 128
Learning rate: 0.0003
Number of parameters: 20,447,232

Initializing dataloaders...
Found 117,133 workflow files in /home/josch/Desktop/data/workflows/json
Loading tokenized workflows from cache: /home/josch/Desktop/data/workflows/json/.cache/tokenized_split90_117133files.pt
âœ… Loaded 117133 tokenized workflows

TRAIN split: 105,419 workflows
Average workflow length: 1758 tokens
Workflows truncated (>4096): 9,219 (8.7%)
Workflows padded (<4096): 96,195 (91.3%)

First batch shape: x=torch.Size([8, 4096]), y=torch.Size([8, 4096])
First batch dtype: x=torch.int32, y=torch.int64

================================================================================
STARTING TRAINING
================================================================================

Found 117,133 workflow files in /home/josch/Desktop/data/workflows/json
Loading tokenized workflows from cache: /home/josch/Desktop/data/workflows/json/.cache/tokenized_split90_117133files.pt
âœ… Loaded 117133 tokenized workflows

VAL split: 11,714 workflows
Average workflow length: 1734 tokens
Workflows truncated (>4096): 1,078 (9.2%)
Workflows padded (<4096): 10,635 (90.8%)

Step 00000 | Val loss: 9.0109 | Val ppl: 8192.00
  âœ¨ New best validation loss!
step 00000/100000 (0.0%) | loss: 9.0109 | ppl: 8192.0 | lr: 6.00e-08 | dt: 4257ms | tok/s: 123,161 | time: 0.0m
step 00010/100000 (0.0%) | loss: 9.0107 | ppl: 8190.1 | lr: 6.60e-07 | dt: 3629ms | tok/s: 144,455 | time: 0.0m
step 00020/100000 (0.0%) | loss: 9.0098 | ppl: 8182.5 | lr: 1.26e-06 | dt: 3679ms | tok/s: 142,525 | time: 0.6m
step 00030/100000 (0.0%) | loss: 9.0074 | ppl: 8163.5 | lr: 1.86e-06 | dt: 3660ms | tok/s: 143,251 | time: 1.2m
step 00040/100000 (0.0%) | loss: 9.0020 | ppl: 8119.0 | lr: 2.46e-06 | dt: 3638ms | tok/s: 144,098 | time: 1.8m
step 00050/100000 (0.1%) | loss: 8.9915 | ppl: 8034.8 | lr: 3.06e-06 | dt: 3652ms | tok/s: 143,566 | time: 2.4m
step 00060/100000 (0.1%) | loss: 8.9742 | ppl: 7896.6 | lr: 3.66e-06 | dt: 3612ms | tok/s: 145,133 | time: 3.0m
step 00070/100000 (0.1%) | loss: 8.9495 | ppl: 7703.7 | lr: 4.26e-06 | dt: 3603ms | tok/s: 145,524 | time: 3.6m
step 00080/100000 (0.1%) | loss: 8.9182 | ppl: 7466.8 | lr: 4.86e-06 | dt: 3613ms | tok/s: 145,125 | time: 4.2m
